{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from numba.cuda import detect\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from typing import List, Optional\n",
    "from omegaconf import OmegaConf\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import wandb\n",
    "import logging\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "\n",
    "from datasets.my_dataset import MyDataset\n",
    "from utils.misc import import_str\n",
    "from models.trainers import BasicTrainer\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c717672bf7f74b44",
   "metadata": {},
   "source": [
    "data_root = \"/mnt/e/Output/background/023_test\"\n",
    "\n",
    "cfg = OmegaConf.load(os.path.join(data_root, \"config.yaml\"))\n",
    "%cd /home/a/drivestudio\n",
    "cfg.data.data_root = \"data/waymo/processed/training\"\n",
    "\n",
    "dataset = MyDataset(cfg.data)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d8c90179b4b29f22",
   "metadata": {},
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "trainer = import_str(cfg.trainer.type)(\n",
    "    **cfg.trainer,\n",
    "    num_timesteps=dataset.num_img_timesteps,\n",
    "    model_config=cfg.model,\n",
    "    num_train_images=len(dataset.train_image_set),\n",
    "    num_full_images=len(dataset.full_image_set),\n",
    "    test_set_indices=dataset.test_timesteps,\n",
    "    scene_aabb=dataset.get_aabb().reshape(2, 3),\n",
    "    device=device\n",
    "\n",
    ")\n",
    "ckpt_path = os.path.join(data_root, \"checkpoint_10000.pth\")\n",
    "\n",
    "trainer.resume_from_checkpoint(\n",
    "    ckpt_path=ckpt_path,\n",
    "    load_only_model=True\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "82d2759cc7170d8e",
   "metadata": {},
   "source": [
    "import pyiqa\n",
    "import random\n",
    "\n",
    "device = trainer.device\n",
    "render_dir = os.path.join(cfg.log_dir, f\"render\")\n",
    "pred_dir = os.path.join(cfg.log_dir, f\"pred\")\n",
    "\n",
    "os.makedirs(render_dir, exist_ok=True)\n",
    "for file in os.listdir(render_dir):\n",
    "    if file.endswith(\".png\"):\n",
    "        os.remove(os.path.join(render_dir, file))\n",
    "\n",
    "# os.makedirs(pred_dir, exist_ok=True)\n",
    "# for file in os.listdir(pred_dir):\n",
    "#     if file.endswith(\".png\"):\n",
    "#         os.remove(os.path.join(pred_dir, file))\n",
    "\n",
    "# iqa_metric = pyiqa.create_metric('brisque', device=device)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0))"
   ],
   "id": "85098b2f1d87141a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from datasets.my_dataset import get_fake_gt_samples\n",
    "random.seed(0)\n",
    "cam2worlds, intrinsics, norm_times, step_times, depth_maps = get_fake_gt_samples(dataset, min_coverage=0.6, max_coverage=0.8, num_points=100)"
   ],
   "id": "163d677712640abb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from matplotlib import pyplot as plt\n",
    "d = depth_maps[0].numpy()\n",
    "plt.imshow(d)"
   ],
   "id": "73fbd41052d69d02",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "564ba730eb58c829",
   "metadata": {},
   "source": [
    "image_info_list, cam_info_list = [], []\n",
    "width, height = 960, 640\n",
    "from utils.visualization import to8b\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "for idx in range(len(cam2worlds)):\n",
    "    c2w = cam2worlds[idx]\n",
    "    intrinsic = intrinsics[idx]\n",
    "    depth_map = depth_maps[idx]\n",
    "    step_time = step_times[idx]\n",
    "    norm_time = norm_times[idx]\n",
    "\n",
    "\n",
    "    cam_info = {\n",
    "        \"camera_to_world\": c2w.to(device),\n",
    "        \"intrinsics\": intrinsic.to(device),\n",
    "        \"height\": torch.tensor(height, dtype=torch.long, device=device),\n",
    "        \"width\": torch.tensor(width, dtype=torch.long, device=device),\n",
    "    }\n",
    "\n",
    "    x, y = torch.meshgrid(\n",
    "        torch.arange(width),\n",
    "        torch.arange(height),\n",
    "        indexing=\"xy\",\n",
    "    )\n",
    "    x, y = x.flatten(), y.flatten()\n",
    "    x, y = x.to(device), y.to(device)\n",
    "\n",
    "    pixel_coords = (\n",
    "        torch.stack([y / height, x / width], dim=-1)\n",
    "        .float()\n",
    "        .reshape(height, width, 2)\n",
    "    )\n",
    "    from datasets.base.pixel_source import get_rays\n",
    "\n",
    "    intrinsic = intrinsic * dataset.pixel_source.downscale_factor\n",
    "    intrinsic[2, 2] = 1.0\n",
    "    intrinsic = intrinsic.to(device)\n",
    "    c2w = c2w.to(device)\n",
    "    origins, viewdirs, direction_norm = get_rays(x, y, c2w, intrinsic)\n",
    "\n",
    "    viewdirs = viewdirs.reshape(height, width, 3)\n",
    "\n",
    "    image_id = torch.full(\n",
    "        (height, width),\n",
    "        0,\n",
    "        dtype=torch.long,\n",
    "    )\n",
    "\n",
    "    normalized_time = torch.full(\n",
    "        (height, width),\n",
    "        norm_time,\n",
    "        dtype=torch.float32,\n",
    "    )\n",
    "\n",
    "    image_info = {\n",
    "        \"origins\": origins.to(device),\n",
    "        \"direction_norm\": direction_norm.to(device),\n",
    "        \"viewdirs\": viewdirs.to(device),\n",
    "        \"img_idx\": image_id.to(device),\n",
    "        \"pixel_coords\": pixel_coords.to(device),\n",
    "        \"normed_time\": normalized_time.to(device),\n",
    "        \"depth_map\": depth_map.to(device),\n",
    "\n",
    "    }\n",
    "    # train_step_camera_downscale = trainer._get_downscale_factor()\n",
    "    # image_info, cam_info = dataset.train_image_set[idx]\n",
    "    # for k, v in image_info.items():\n",
    "    #     if isinstance(v, torch.Tensor):\n",
    "    #         image_info[k] = v.cuda(non_blocking=True)\n",
    "    # for k, v in cam_info.items():\n",
    "    #     if isinstance(v, torch.Tensor):\n",
    "    #         cam_info[k] = v.cuda(non_blocking=True)\n",
    "\n",
    "    output = trainer(image_info, cam_info, False)\n",
    "\n",
    "    sky_mask = output[\"opacity\"].cpu().detach()\n",
    "    sky_mask = sky_mask.reshape(height, width)\n",
    "    sky_mask = (sky_mask > 0.5).float()\n",
    "\n",
    "    image_info[\"sky_masks\"] = sky_mask.to(device)\n",
    "\n",
    "    img = to8b(output[\"rgb\"])\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # iqa_img = torch.from_numpy(img).permute(2, 0, 1).unsqueeze(0).to(device)\n",
    "\n",
    "    # score = iqa_metric(iqa_img)\n",
    "    # if score > 60:\n",
    "    #     continue\n",
    "\n",
    "    save_path = os.path.join(render_dir, f\"{idx:03d}.png\")\n",
    "    cv2.imwrite(save_path, img)\n",
    "\n",
    "    image_info_list.append(image_info)\n",
    "    cam_info_list.append(cam_info)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "88effc3cc46d105b",
   "metadata": {},
   "source": [
    "for idx in range(len(cam2worlds)):\n",
    "    render_img_path = os.path.join(render_dir, f\"{idx:03d}.png\")\n",
    "    pred_img_path = os.path.join(pred_dir, f\"{idx:03d}.png\")\n",
    "\n",
    "    if not (os.path.exists(render_img_path) and os.path.exists(pred_img_path)):\n",
    "        print(pred_img_path)\n",
    "        continue\n",
    "\n",
    "    pred_img = cv2.imread(pred_img_path)\n",
    "    pred_img = cv2.cvtColor(pred_img, cv2.COLOR_RGB2BGR)\n",
    "    pred_img = torch.from_numpy(pred_img).float() / 255.0\n",
    "\n",
    "    image_info_list[idx][\"pixels\"] = pred_img.to(device)\n",
    "\n",
    "to_delete = [idx for idx, image_info in enumerate(image_info_list)  if \"pixels\" not in image_info]\n",
    "for idx in reversed(to_delete):\n",
    "    del image_info_list[idx]\n",
    "    del cam_info_list[idx]\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "dataset.load_fake_gt(image_info_list, cam_info_list, True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "torch.save(image_info_list, \"notebook/data/image_info_list_023_test.pth\")\n",
    "torch.save(cam_info_list, \"notebook/data/cam_info_list_023_test.pth\")\n",
    "# image_info_list = torch.load(\"notebook/data/image_info_list.pth\")\n",
    "# cam_info_list = torch.load(\"notebook/data/cam_info_list.pth\")\n",
    "# dataset.load_fake_gt(image_info_list, cam_info_list, True)\n"
   ],
   "id": "2609918a24df7cb6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "trainer.init_gaussians_from_dataset(dataset=dataset)\n",
    "trainer.initialize_optimizer()\n",
    "trainer.init_viewer(8080)"
   ],
   "id": "138016f2f9fe9bb7",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c9cc5b994cc66d1d",
   "metadata": {},
   "source": [
    "\n",
    "for step in range(0, 10000):\n",
    "    #----------------------------------------------------------------------------\n",
    "    #----------------------------  training step  -------------------------------\n",
    "    if step % 100 == 0:\n",
    "        print(step)\n",
    "    # prepare for training\n",
    "    trainer.set_train()\n",
    "    trainer.preprocess_per_train_step(step=step)\n",
    "\n",
    "    trainer.optimizer_zero_grad() # zero grad\n",
    "    # get data\n",
    "    use_fake_gt = random.random() < 0.1\n",
    "    if use_fake_gt and step > 500:\n",
    "        image_infos, cam_infos = dataset.fake_gt_next()\n",
    "    else:\n",
    "        train_step_camera_downscale = trainer._get_downscale_factor()\n",
    "        image_infos, cam_infos = dataset.train_image_set.next(train_step_camera_downscale)\n",
    "    for k, v in image_infos.items():\n",
    "        if isinstance(v, torch.Tensor):\n",
    "            image_infos[k] = v.cuda(non_blocking=True)\n",
    "    for k, v in cam_infos.items():\n",
    "        if isinstance(v, torch.Tensor):\n",
    "            cam_infos[k] = v.cuda(non_blocking=True)\n",
    "\n",
    "    # forward & backward\n",
    "    outputs = trainer(image_infos, cam_infos, False)\n",
    "    trainer.update_visibility_filter()\n",
    "    loss_dict = trainer.compute_losses(\n",
    "        outputs=outputs,\n",
    "        image_infos=image_infos,\n",
    "        cam_infos=cam_infos,\n",
    "    )\n",
    "    # check nan or inf\n",
    "    for k, v in loss_dict.items():\n",
    "        if torch.isnan(v).any():\n",
    "            raise ValueError(f\"NaN detected in loss {k} at step {step}\")\n",
    "        if torch.isinf(v).any():\n",
    "            raise ValueError(f\"Inf detected in loss {k} at step {step}\")\n",
    "    trainer.backward(loss_dict)\n",
    "\n",
    "    # after training step\n",
    "    trainer.postprocess_per_train_step(step=step)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "26f56c4a53d0a32f",
   "metadata": {},
   "source": [
    "trainer.save_checkpoint(\n",
    "    log_dir=cfg.log_dir,\n",
    "    save_only_model=True,\n",
    "    is_final=False,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b65798ca49ef44ee",
   "metadata": {},
   "source": [
    "dataset.pixel_source.camera_data"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f5b82d4b6c122d15",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
