{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-22T12:43:54.856037Z",
     "start_time": "2024-12-22T12:43:49.809065Z"
    }
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from typing import List, Optional\n",
    "from omegaconf import OmegaConf\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import wandb\n",
    "import logging\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "\n",
    "from datasets.my_dataset import MyDataset\n",
    "from utils.misc import import_str\n",
    "from models.trainers import BasicTrainer\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/a/anaconda3/envs/drivestudio/lib/python3.9/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.20) or chardet (5.2.0)/charset_normalizer (None) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "c717672bf7f74b44",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-12-22T12:44:07.365430Z"
    }
   },
   "source": [
    "data_root = \"/mnt/e/Output/background/023_test\"\n",
    "\n",
    "cfg = OmegaConf.load(os.path.join(data_root, \"config.yaml\"))\n",
    "%cd /home/a/drivestudio\n",
    "cfg.data.data_root = \"data/waymo/processed/training\"\n",
    "\n",
    "dataset = MyDataset(cfg.data)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/a/drivestudio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images:   3%|▎         | 5/199 [00:00<00:04, 43.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "undistorting rgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images: 100%|██████████| 199/199 [00:04<00:00, 44.52it/s]\n",
      "Loading dynamic masks:   4%|▍         | 8/199 [00:00<00:02, 79.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "undistorting dynamic mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dynamic masks: 100%|██████████| 199/199 [00:02<00:00, 80.71it/s]\n",
      "Loading human masks:   5%|▍         | 9/199 [00:00<00:02, 81.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "undistorting human mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading human masks: 100%|██████████| 199/199 [00:02<00:00, 83.53it/s]\n",
      "Loading vehicle masks:   5%|▍         | 9/199 [00:00<00:02, 84.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "undistorting vehicle mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading vehicle masks: 100%|██████████| 199/199 [00:02<00:00, 84.23it/s]\n",
      "Loading sky masks:   6%|▌         | 12/199 [00:00<00:01, 113.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "undistorting sky mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading sky masks: 100%|██████████| 199/199 [00:01<00:00, 114.99it/s]\n",
      "Loading images:   5%|▌         | 10/199 [00:00<00:03, 48.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "undistorting rgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images: 100%|██████████| 199/199 [00:03<00:00, 51.95it/s]\n",
      "Loading dynamic masks:   5%|▍         | 9/199 [00:00<00:02, 80.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "undistorting dynamic mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dynamic masks: 100%|██████████| 199/199 [00:02<00:00, 78.38it/s]\n",
      "Loading human masks:   5%|▍         | 9/199 [00:00<00:02, 81.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "undistorting human mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading human masks: 100%|██████████| 199/199 [00:02<00:00, 81.92it/s]\n",
      "Loading vehicle masks:   5%|▍         | 9/199 [00:00<00:02, 82.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "undistorting vehicle mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading vehicle masks: 100%|██████████| 199/199 [00:02<00:00, 81.30it/s]\n",
      "Loading sky masks:   6%|▌         | 11/199 [00:00<00:01, 109.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "undistorting sky mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading sky masks: 100%|██████████| 199/199 [00:01<00:00, 112.71it/s]\n",
      "Loading images:   5%|▌         | 10/199 [00:00<00:03, 48.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "undistorting rgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images: 100%|██████████| 199/199 [00:04<00:00, 49.26it/s]\n",
      "Loading dynamic masks:   5%|▍         | 9/199 [00:00<00:02, 82.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "undistorting dynamic mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dynamic masks: 100%|██████████| 199/199 [00:02<00:00, 66.79it/s]\n",
      "Loading human masks:   5%|▍         | 9/199 [00:00<00:02, 82.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "undistorting human mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading human masks: 100%|██████████| 199/199 [00:02<00:00, 82.16it/s]\n",
      "Loading vehicle masks:   5%|▍         | 9/199 [00:00<00:02, 83.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "undistorting vehicle mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading vehicle masks: 100%|██████████| 199/199 [00:02<00:00, 83.70it/s]\n",
      "Loading sky masks:  12%|█▏        | 24/199 [00:00<00:01, 115.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "undistorting sky mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading sky masks: 100%|██████████| 199/199 [00:01<00:00, 115.11it/s]\n",
      "Loading images:   8%|▊         | 15/199 [00:00<00:02, 71.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "undistorting rgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images: 100%|██████████| 199/199 [00:02<00:00, 70.11it/s]\n",
      "Loading dynamic masks:   6%|▌         | 11/199 [00:00<00:01, 103.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "undistorting dynamic mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dynamic masks: 100%|██████████| 199/199 [00:01<00:00, 106.21it/s]\n",
      "Loading human masks:   6%|▌         | 11/199 [00:00<00:01, 105.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "undistorting human mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading human masks: 100%|██████████| 199/199 [00:01<00:00, 103.62it/s]\n",
      "Loading vehicle masks:  11%|█         | 22/199 [00:00<00:01, 106.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "undistorting vehicle mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading vehicle masks: 100%|██████████| 199/199 [00:01<00:00, 104.58it/s]\n",
      "Loading sky masks:   8%|▊         | 15/199 [00:00<00:01, 141.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "undistorting sky mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading sky masks: 100%|██████████| 199/199 [00:01<00:00, 143.70it/s]\n",
      "Loading images:   8%|▊         | 16/199 [00:00<00:02, 75.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "undistorting rgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images: 100%|██████████| 199/199 [00:02<00:00, 71.80it/s]\n",
      "Loading dynamic masks:   6%|▌         | 12/199 [00:00<00:01, 111.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "undistorting dynamic mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dynamic masks: 100%|██████████| 199/199 [00:01<00:00, 109.09it/s]\n",
      "Loading human masks:   6%|▌         | 11/199 [00:00<00:01, 107.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "undistorting human mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading human masks: 100%|██████████| 199/199 [00:01<00:00, 105.38it/s]\n",
      "Loading vehicle masks:   6%|▌         | 11/199 [00:00<00:01, 106.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "undistorting vehicle mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading vehicle masks: 100%|██████████| 199/199 [00:01<00:00, 99.95it/s] \n",
      "Loading sky masks:   7%|▋         | 14/199 [00:00<00:01, 131.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "undistorting sky mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading sky masks: 100%|██████████| 199/199 [00:01<00:00, 134.13it/s]\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d8c90179b4b29f22",
   "metadata": {},
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "trainer = import_str(cfg.trainer.type)(\n",
    "    **cfg.trainer,\n",
    "    num_timesteps=dataset.num_img_timesteps,\n",
    "    model_config=cfg.model,\n",
    "    num_train_images=len(dataset.train_image_set),\n",
    "    num_full_images=len(dataset.full_image_set),\n",
    "    test_set_indices=dataset.test_timesteps,\n",
    "    scene_aabb=dataset.get_aabb().reshape(2, 3),\n",
    "    device=device\n",
    "\n",
    ")\n",
    "ckpt_path = os.path.join(data_root, \"checkpoint_10000.pth\")\n",
    "\n",
    "trainer.resume_from_checkpoint(\n",
    "    ckpt_path=ckpt_path,\n",
    "    load_only_model=True\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "82d2759cc7170d8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T12:45:22.913621900Z",
     "start_time": "2024-12-22T12:31:57.496922Z"
    }
   },
   "source": [
    "import pyiqa\n",
    "import random\n",
    "\n",
    "device = trainer.device\n",
    "render_dir = os.path.join(cfg.log_dir, f\"render\")\n",
    "pred_dir = os.path.join(cfg.log_dir, f\"pred\")\n",
    "\n",
    "os.makedirs(render_dir, exist_ok=True)\n",
    "for file in os.listdir(render_dir):\n",
    "    if file.endswith(\".png\"):\n",
    "        os.remove(os.path.join(render_dir, file))\n",
    "\n",
    "os.makedirs(pred_dir, exist_ok=True)\n",
    "for file in os.listdir(pred_dir):\n",
    "    if file.endswith(\".png\"):\n",
    "        os.remove(os.path.join(pred_dir, file))\n",
    "\n",
    "# iqa_metric = pyiqa.create_metric('brisque', device=device)"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T12:32:07.483702Z",
     "start_time": "2024-12-22T12:31:59.140221Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets.my_dataset import get_fake_gt_samples\n",
    "\n",
    "cam2worlds, intrinsics = get_fake_gt_samples(dataset, min_coverage=0.4, max_coverage=0.8, num_points=100)"
   ],
   "id": "163d677712640abb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "cam2worlds.shape",
   "id": "73fbd41052d69d02",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "564ba730eb58c829",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T12:32:28.637035Z",
     "start_time": "2024-12-22T12:32:18.084729Z"
    }
   },
   "source": [
    "image_info_list, cam_info_list = [], []\n",
    "width, height = 960, 640\n",
    "from utils.visualization import to8b\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "for idx in range(len(cam2worlds)):\n",
    "    c2w = cam2worlds[idx]\n",
    "    intrinsic = intrinsics[idx]\n",
    "\n",
    "\n",
    "    cam_info = {\n",
    "        \"camera_to_world\": c2w.to(device),\n",
    "        \"intrinsics\": intrinsic.to(device),\n",
    "        \"height\": torch.tensor(height, dtype=torch.long, device=device),\n",
    "        \"width\": torch.tensor(width, dtype=torch.long, device=device),\n",
    "    }\n",
    "\n",
    "    x, y = torch.meshgrid(\n",
    "        torch.arange(width),\n",
    "        torch.arange(height),\n",
    "        indexing=\"xy\",\n",
    "    )\n",
    "    x, y = x.flatten(), y.flatten()\n",
    "    x, y = x.to(device), y.to(device)\n",
    "\n",
    "    pixel_coords = (\n",
    "        torch.stack([y / height, x / width], dim=-1)\n",
    "        .float()\n",
    "        .reshape(height, width, 2)\n",
    "    )\n",
    "    from datasets.base.pixel_source import get_rays\n",
    "\n",
    "    intrinsic = intrinsic * dataset.pixel_source.downscale_factor\n",
    "    intrinsic[2, 2] = 1.0\n",
    "    intrinsic = intrinsic.to(device)\n",
    "    c2w = c2w.to(device)\n",
    "    origins, viewdirs, direction_norm = get_rays(x, y, c2w, intrinsic)\n",
    "\n",
    "    viewdirs = viewdirs.reshape(height, width, 3)\n",
    "\n",
    "    image_id = torch.full(\n",
    "        (height, width),\n",
    "        0,\n",
    "        dtype=torch.long,\n",
    "    )\n",
    "\n",
    "    time_step = dataset.pixel_source.normalized_time.shape\n",
    "    t = random.randint(0, time_step[0] - 1)\n",
    "\n",
    "    normalized_time = torch.full(\n",
    "        (height, width),\n",
    "        dataset.pixel_source.normalized_time[t],\n",
    "        dtype=torch.float32,\n",
    "    )\n",
    "\n",
    "    image_info = {\n",
    "        \"origins\": origins.to(device),\n",
    "        \"direction_norm\": direction_norm.to(device),\n",
    "        \"viewdirs\": viewdirs.to(device),\n",
    "        \"img_idx\": image_id.to(device),\n",
    "        \"pixel_coords\": pixel_coords.to(device),\n",
    "        \"normed_time\": normalized_time.to(device),\n",
    "    }\n",
    "    # train_step_camera_downscale = trainer._get_downscale_factor()\n",
    "    # image_info, cam_info = dataset.train_image_set[idx]\n",
    "    # for k, v in image_info.items():\n",
    "    #     if isinstance(v, torch.Tensor):\n",
    "    #         image_info[k] = v.cuda(non_blocking=True)\n",
    "    # for k, v in cam_info.items():\n",
    "    #     if isinstance(v, torch.Tensor):\n",
    "    #         cam_info[k] = v.cuda(non_blocking=True)\n",
    "\n",
    "    output = trainer(image_info, cam_info, False)\n",
    "\n",
    "    sky_mask = output[\"opacity\"].cpu().detach()\n",
    "    sky_mask = sky_mask.reshape(height, width)\n",
    "    sky_mask = (sky_mask > 0.5).float()\n",
    "\n",
    "    image_info[\"sky_masks\"] = sky_mask.to(device)\n",
    "\n",
    "    img = to8b(output[\"rgb\"])\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # iqa_img = torch.from_numpy(img).permute(2, 0, 1).unsqueeze(0).to(device)\n",
    "\n",
    "    # score = iqa_metric(iqa_img)\n",
    "    # if score > 60:\n",
    "    #     continue\n",
    "\n",
    "    save_path = os.path.join(render_dir, f\"{idx:03d}.png\")\n",
    "    cv2.imwrite(save_path, img)\n",
    "\n",
    "    image_info_list.append(image_info)\n",
    "    cam_info_list.append(cam_info)"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "88effc3cc46d105b",
   "metadata": {},
   "source": [
    "for idx in range(len(cam2worlds)):\n",
    "    render_img_path = os.path.join(render_dir, f\"{idx:03d}.png\")\n",
    "    pred_img_path = os.path.join(pred_dir, f\"{idx:03d}.png\")\n",
    "\n",
    "    if not (os.path.exists(render_img_path) and os.path.exists(pred_img_path)):\n",
    "        print(pred_img_path)\n",
    "        continue\n",
    "\n",
    "    pred_img = cv2.imread(pred_img_path)\n",
    "    pred_img = cv2.cvtColor(pred_img, cv2.COLOR_RGB2BGR)\n",
    "    pred_img = torch.from_numpy(pred_img).float() / 255.0\n",
    "\n",
    "    image_info_list[idx][\"pixels\"] = pred_img.to(device)\n",
    "\n",
    "to_delete = [idx for idx, image_info in enumerate(image_info_list)  if \"pixels\" not in image_info]\n",
    "for idx in reversed(to_delete):\n",
    "    del image_info_list[idx]\n",
    "    del cam_info_list[idx]\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "dataset.load_fake_gt(image_info_list, cam_info_list, True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "torch.save(image_info_list, \"notebook/data/image_info_list_023_test.pth\")\n",
    "torch.save(cam_info_list, \"notebook/data/cam_info_list_023_test.pth\")\n",
    "# image_info_list = torch.load(\"notebook/data/image_info_list.pth\")\n",
    "# cam_info_list = torch.load(\"notebook/data/cam_info_list.pth\")\n",
    "# dataset.load_fake_gt(image_info_list, cam_info_list, True)\n"
   ],
   "id": "2609918a24df7cb6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "trainer.init_gaussians_from_dataset(dataset=dataset)\n",
    "trainer.initialize_optimizer()\n",
    "trainer.init_viewer(8080)"
   ],
   "id": "138016f2f9fe9bb7",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c9cc5b994cc66d1d",
   "metadata": {},
   "source": [
    "\n",
    "for step in range(0, 10000):\n",
    "    #----------------------------------------------------------------------------\n",
    "    #----------------------------  training step  -------------------------------\n",
    "    if step % 100 == 0:\n",
    "        print(step)\n",
    "    # prepare for training\n",
    "    trainer.set_train()\n",
    "    trainer.preprocess_per_train_step(step=step)\n",
    "\n",
    "    trainer.optimizer_zero_grad() # zero grad\n",
    "    # get data\n",
    "    use_fake_gt = random.random() < 0.1\n",
    "    if use_fake_gt and step > 500:\n",
    "        image_infos, cam_infos = dataset.fake_gt_next()\n",
    "    else:\n",
    "        train_step_camera_downscale = trainer._get_downscale_factor()\n",
    "        image_infos, cam_infos = dataset.train_image_set.next(train_step_camera_downscale)\n",
    "    for k, v in image_infos.items():\n",
    "        if isinstance(v, torch.Tensor):\n",
    "            image_infos[k] = v.cuda(non_blocking=True)\n",
    "    for k, v in cam_infos.items():\n",
    "        if isinstance(v, torch.Tensor):\n",
    "            cam_infos[k] = v.cuda(non_blocking=True)\n",
    "\n",
    "    # forward & backward\n",
    "    outputs = trainer(image_infos, cam_infos, ~ use_fake_gt)\n",
    "    trainer.update_visibility_filter()\n",
    "    loss_dict = trainer.compute_losses(\n",
    "        outputs=outputs,\n",
    "        image_infos=image_infos,\n",
    "        cam_infos=cam_infos,\n",
    "    )\n",
    "    # check nan or inf\n",
    "    for k, v in loss_dict.items():\n",
    "        if torch.isnan(v).any():\n",
    "            raise ValueError(f\"NaN detected in loss {k} at step {step}\")\n",
    "        if torch.isinf(v).any():\n",
    "            raise ValueError(f\"Inf detected in loss {k} at step {step}\")\n",
    "    trainer.backward(loss_dict)\n",
    "\n",
    "    # after training step\n",
    "    trainer.postprocess_per_train_step(step=step)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "26f56c4a53d0a32f",
   "metadata": {},
   "source": [
    "trainer.save_checkpoint(\n",
    "    log_dir=cfg.log_dir,\n",
    "    save_only_model=True,\n",
    "    is_final=False,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b65798ca49ef44ee",
   "metadata": {},
   "source": [
    "dataset.pixel_source.camera_data"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f5b82d4b6c122d15",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
