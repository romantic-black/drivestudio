{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from typing import List, Optional\n",
    "from omegaconf import OmegaConf\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import wandb\n",
    "import logging\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "from datasets.driving_dataset import DrivingDataset\n",
    "from datasets.my_dataset import MyDataset\n",
    "from utils.misc import import_str\n",
    "from models.trainers import BasicTrainer\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cfg = OmegaConf.load(os.path.join(\"/mnt/e/Output/background/149\", \"config.yaml\"))\n",
    "%cd /home/a/drivestudio\n",
    "\n",
    "dataset = MyDataset(cfg.data)"
   ],
   "id": "c717672bf7f74b44",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "trainer = import_str(cfg.trainer.type)(\n",
    "    **cfg.trainer,\n",
    "    num_timesteps=dataset.num_img_timesteps,\n",
    "    model_config=cfg.model,\n",
    "    num_train_images=len(dataset.train_image_set),\n",
    "    num_full_images=len(dataset.full_image_set),\n",
    "    test_set_indices=dataset.test_timesteps,\n",
    "    scene_aabb=dataset.get_aabb().reshape(2, 3),\n",
    "    device=device\n",
    "\n",
    ")\n",
    "\n",
    "trainer.resume_from_checkpoint(\n",
    "    ckpt_path=\"/mnt/e/Output/background/149/checkpoint_final.pth\",\n",
    "    load_only_model=True\n",
    ")"
   ],
   "id": "d8c90179b4b29f22",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T13:26:59.847092Z",
     "start_time": "2024-12-18T13:26:46.675427Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "cam2worlds = torch.load(\"notebook/data/cam2worlds.pth\")\n",
    "intrinsics = torch.load(\"notebook/data/intrinsics.pth\")\n",
    "width, height = 960, 640\n",
    "\n",
    "for idx in range(len(cam2worlds)):\n",
    "    c2w = cam2worlds[idx]\n",
    "    intrinsic = intrinsics[idx]\n",
    "    name = \"fake_truth\"\n",
    "\n",
    "    a, b = dataset.pixel_source.get_image(0)\n",
    "    device = trainer.device\n",
    "\n",
    "    cam_info = {\n",
    "        \"camera_to_world\": c2w.to(device),\n",
    "        \"intrinsics\": intrinsic.to(device),\n",
    "        \"height\": torch.tensor(height, dtype=torch.long, device=device),\n",
    "        \"width\": torch.tensor(width, dtype=torch.long, device=device),\n",
    "    }\n",
    "\n",
    "    x, y = torch.meshgrid(\n",
    "        torch.arange(width),\n",
    "        torch.arange(height),\n",
    "        indexing=\"xy\",\n",
    "    )\n",
    "    x, y = x.flatten(), y.flatten()\n",
    "    x, y = x.to(device), y.to(device)\n",
    "\n",
    "    pixel_coords = (\n",
    "        torch.stack([y / height, x / width], dim=-1)\n",
    "        .float()\n",
    "        .reshape(height, width, 2)\n",
    "    )\n",
    "    from datasets.base.pixel_source import get_rays\n",
    "\n",
    "    intrinsic = intrinsic * dataset.pixel_source.downscale_factor\n",
    "    intrinsic[2, 2] = 1.0\n",
    "    intrinsic = intrinsic.to(device)\n",
    "    c2w = c2w.to(device)\n",
    "    _, viewdirs, _ = get_rays(x, y, c2w, intrinsic)\n",
    "\n",
    "    viewdirs = viewdirs.reshape(height, width, 3)\n",
    "\n",
    "    image_id = torch.full(\n",
    "        (height, width),\n",
    "        0,\n",
    "        dtype=torch.long,\n",
    "    )\n",
    "\n",
    "    frame_idx = 0\n",
    "\n",
    "    normalized_time = torch.full(\n",
    "        (height, width),\n",
    "        dataset.pixel_source.normalized_time[0],\n",
    "        dtype=torch.float32,\n",
    "    )\n",
    "\n",
    "    image_info = {\n",
    "        \"viewdirs\": viewdirs.to(device),\n",
    "        \"img_idx\": image_id.to(device),\n",
    "        \"pixel_coords\": pixel_coords.to(device),\n",
    "        \"normed_time\": normalized_time.to(device),\n",
    "    }\n",
    "\n",
    "    output = trainer(image_info, cam_info, False)\n",
    "    from utils.visualization import to8b\n",
    "    import cv2\n",
    "    img = to8b(output[\"rgb\"])\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    cv2.imwrite(f\"/mnt/e/Output/background/149/render/{idx}.png\",img)"
   ],
   "id": "564ba730eb58c829",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from utils.visualization import to8b\n",
    "import cv2\n",
    "img = to8b(output[\"rgb_sky_blend\"])\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "cv2.imwrite(f\"/mnt/e/Output/background/149/render/sky.png\",img)"
   ],
   "id": "6327622d6c73c7f1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "output[\"rgb_sky_blend\"]",
   "id": "db84530d8913846f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "320f1717df17d85b",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
