{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T05:13:26.138644Z",
     "start_time": "2024-12-17T05:13:21.323832Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "from mpmath.tests.runtests import coverage\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from typing import List, Optional\n",
    "from omegaconf import OmegaConf\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import wandb\n",
    "import logging\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from datasets.driving_dataset import DrivingDataset\n",
    "from datasets.my_dataset import MyDataset\n",
    "from utils.misc import import_str\n",
    "from models.trainers import BasicTrainer\n",
    "from models.video_utils import (\n",
    "    render_images,\n",
    "    save_videos,\n",
    "    render_novel_views\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8e12b511020a114",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T05:15:48.836345Z",
     "start_time": "2024-12-17T05:13:26.149917Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/a/drivestudio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images:   4%|▍         | 8/199 [00:00<00:05, 37.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "undistorting rgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images: 100%|██████████| 199/199 [00:05<00:00, 38.05it/s]\n",
      "Loading dynamic masks:   6%|▌         | 12/199 [00:00<00:03, 57.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "undistorting dynamic mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dynamic masks: 100%|██████████| 199/199 [00:03<00:00, 57.62it/s]\n",
      "Loading human masks:   3%|▎         | 6/199 [00:00<00:03, 55.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "undistorting human mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading human masks: 100%|██████████| 199/199 [00:03<00:00, 60.47it/s]\n",
      "Loading vehicle masks:   4%|▎         | 7/199 [00:00<00:03, 63.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "undistorting vehicle mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading vehicle masks: 100%|██████████| 199/199 [00:03<00:00, 65.17it/s]\n",
      "Loading sky masks:   5%|▌         | 10/199 [00:00<00:02, 92.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "undistorting sky mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading sky masks: 100%|██████████| 199/199 [00:02<00:00, 99.50it/s] \n",
      "Loading images:   3%|▎         | 5/199 [00:00<00:04, 40.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "undistorting rgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images: 100%|██████████| 199/199 [00:04<00:00, 40.06it/s]\n",
      "Loading dynamic masks:   4%|▎         | 7/199 [00:00<00:03, 63.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "undistorting dynamic mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dynamic masks: 100%|██████████| 199/199 [00:03<00:00, 65.05it/s]\n",
      "Loading human masks:   7%|▋         | 13/199 [00:00<00:02, 64.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "undistorting human mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading human masks: 100%|██████████| 199/199 [00:02<00:00, 72.50it/s]\n",
      "Loading vehicle masks:   8%|▊         | 16/199 [00:00<00:02, 79.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "undistorting vehicle mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading vehicle masks: 100%|██████████| 199/199 [00:02<00:00, 75.84it/s]\n",
      "Loading sky masks:  11%|█         | 22/199 [00:00<00:01, 109.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "undistorting sky mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading sky masks: 100%|██████████| 199/199 [00:01<00:00, 109.17it/s]\n",
      "Loading images:   4%|▍         | 8/199 [00:00<00:04, 38.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "undistorting rgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images: 100%|██████████| 199/199 [00:05<00:00, 38.13it/s]\n",
      "Loading dynamic masks:   4%|▎         | 7/199 [00:00<00:03, 60.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "undistorting dynamic mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dynamic masks: 100%|██████████| 199/199 [00:03<00:00, 65.72it/s]\n",
      "Loading human masks:   4%|▍         | 8/199 [00:00<00:02, 74.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "undistorting human mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading human masks: 100%|██████████| 199/199 [00:02<00:00, 70.48it/s]\n",
      "Loading vehicle masks:   8%|▊         | 16/199 [00:00<00:02, 77.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "undistorting vehicle mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading vehicle masks: 100%|██████████| 199/199 [00:02<00:00, 72.69it/s]\n",
      "Loading sky masks:  11%|█         | 22/199 [00:00<00:01, 107.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "undistorting sky mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading sky masks: 100%|██████████| 199/199 [00:01<00:00, 104.53it/s]\n",
      "Loading images:   3%|▎         | 6/199 [00:00<00:03, 51.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "undistorting rgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images: 100%|██████████| 199/199 [00:03<00:00, 52.96it/s]\n",
      "Loading dynamic masks:   7%|▋         | 14/199 [00:00<00:02, 66.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "undistorting dynamic mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dynamic masks: 100%|██████████| 199/199 [00:02<00:00, 80.31it/s]\n",
      "Loading human masks:   8%|▊         | 16/199 [00:00<00:02, 77.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "undistorting human mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading human masks: 100%|██████████| 199/199 [00:02<00:00, 94.52it/s]\n",
      "Loading vehicle masks:   9%|▊         | 17/199 [00:00<00:02, 81.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "undistorting vehicle mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading vehicle masks: 100%|██████████| 199/199 [00:02<00:00, 97.21it/s] \n",
      "Loading sky masks:  13%|█▎        | 25/199 [00:00<00:01, 124.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "undistorting sky mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading sky masks: 100%|██████████| 199/199 [00:01<00:00, 131.91it/s]\n",
      "Loading images:   5%|▌         | 10/199 [00:00<00:03, 49.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "undistorting rgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images: 100%|██████████| 199/199 [00:03<00:00, 52.18it/s]\n",
      "Loading dynamic masks:   5%|▍         | 9/199 [00:00<00:02, 81.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "undistorting dynamic mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dynamic masks: 100%|██████████| 199/199 [00:02<00:00, 91.92it/s] \n",
      "Loading human masks:  10%|▉         | 19/199 [00:00<00:01, 92.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "undistorting human mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading human masks: 100%|██████████| 199/199 [00:02<00:00, 96.52it/s]\n",
      "Loading vehicle masks:   5%|▍         | 9/199 [00:00<00:02, 85.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "undistorting vehicle mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading vehicle masks: 100%|██████████| 199/199 [00:02<00:00, 98.72it/s] \n",
      "Loading sky masks:   6%|▌         | 11/199 [00:00<00:01, 103.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "undistorting sky mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading sky masks: 100%|██████████| 199/199 [00:01<00:00, 133.59it/s]\n",
      "Loading SMPL: 100%|██████████| 199/199 [00:00<00:00, 684.84it/s] \n",
      "Loading lidar:   0%|          | 0/199 [00:00<?, ?it/s]/home/a/drivestudio/datasets/waymo/waymo_sourceloader.py:411: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  lidar_origins = torch.from_numpy(lidar_info[:, :3]).float()  # 提取原点\n",
      "Loading lidar: 100%|██████████| 199/199 [00:23<00:00,  8.33it/s]\n",
      "Projecting lidar pts on images for camera front_camera: 100%|██████████| 199/199 [00:06<00:00, 33.12it/s]\n",
      "Projecting lidar pts on images for camera front_left_camera: 100%|██████████| 199/199 [00:05<00:00, 33.83it/s]\n",
      "Projecting lidar pts on images for camera front_right_camera: 100%|██████████| 199/199 [00:05<00:00, 33.88it/s]\n",
      "Projecting lidar pts on images for camera left_camera: 100%|██████████| 199/199 [00:06<00:00, 33.03it/s]\n",
      "Projecting lidar pts on images for camera right_camera: 100%|██████████| 199/199 [00:05<00:00, 33.73it/s]\n"
     ]
    }
   ],
   "source": [
    "cfg = OmegaConf.load(os.path.join(\"/mnt/e/Output/cam5/149\", \"config.yaml\"))\n",
    "%cd /home/a/drivestudio\n",
    "\n",
    "dataset = MyDataset(cfg.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ea43612cf6c3427",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T05:15:51.163717Z",
     "start_time": "2024-12-17T05:15:48.883373Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([19016548, 3]), torch.Size([19016548]), torch.Size([19016548]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source = dataset.lidar_source\n",
    "points = source.origins + source.directions * source.ranges\n",
    "grounds = source.grounds\n",
    "flow_class = source.flow_classes\n",
    "points.shape, grounds.shape, flow_class.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4227cecdaa0a5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_lidar_points(lidar_points, ground_mask=None):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.scatter(lidar_points[:, 0][~ground_mask], lidar_points[:, 1][~ground_mask], c='b', s=1)  # 2D scatter plot\n",
    "    plt.title('2D Lidar Points')\n",
    "    plt.xlabel('X Coordinate')\n",
    "    plt.ylabel('Y Coordinate')\n",
    "    plt.axis('equal')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "plot_lidar_points(points.numpy(), grounds.numpy())  # Convert to numpy array for plotting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a942bde98b8abc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def create_voxel_grid_2d(lidar_points, voxel_size=1):\n",
    "    z = lidar_points[:, 2]\n",
    "    lidar_points = lidar_points[(-1 <= z) & (z <= 3)]\n",
    "    x_min, x_max = lidar_points[:, 0].min(), lidar_points[:, 0].max()\n",
    "    y_min, y_max = lidar_points[:, 1].min(), lidar_points[:, 1].max()\n",
    "    \n",
    "    grid_size_x = int((x_max - x_min) / voxel_size) + 1\n",
    "    grid_size_y = int((y_max - y_min) / voxel_size) + 1\n",
    "    \n",
    "    voxel_grid = torch.zeros((grid_size_x, grid_size_y), dtype=torch.int32)\n",
    "    \n",
    "    # 计算每个点的体素索引\n",
    "    voxel_indices_x = ((lidar_points[:, 0] - x_min) / voxel_size).long()\n",
    "    voxel_indices_y = ((lidar_points[:, 1] - y_min) / voxel_size).long()\n",
    "    \n",
    "    # 将二维索引展平成一维索引\n",
    "    flat_indices = voxel_indices_x * grid_size_y + voxel_indices_y\n",
    "    \n",
    "    # 使用 torch.bincount 统计每个体素的点数量\n",
    "    counts = torch.bincount(flat_indices, minlength=grid_size_x * grid_size_y)\n",
    "    \n",
    "    # 将一维结果重塑为二维网格\n",
    "    voxel_grid = counts.view(grid_size_x, grid_size_y)\n",
    "    \n",
    "    return voxel_grid\n",
    "\n",
    "p = points[~grounds]\n",
    "c = flow_class[~grounds]\n",
    "\n",
    "# 生成2D体素网格\n",
    "voxel_grid_2d = create_voxel_grid_2d(p[c<=0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a57a52040ea24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(voxel_grid_2d.numpy() > 3, cmap='hot', interpolation='nearest')\n",
    "plt.title('Voxel Grid')\n",
    "plt.xlabel('Voxel X')\n",
    "plt.ylabel('Voxel Y')\n",
    "plt.colorbar(label='Point Count')\n",
    "plt.axis('equal')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd324945652247b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T05:16:01.357280Z",
     "start_time": "2024-12-17T05:16:01.336313Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: <datasets.waymo.waymo_sourceloader.WaymoCameraData at 0x7f9b527cd850>,\n",
       " 1: <datasets.waymo.waymo_sourceloader.WaymoCameraData at 0x7f9b8dd6a790>,\n",
       " 2: <datasets.waymo.waymo_sourceloader.WaymoCameraData at 0x7f9b527d3850>,\n",
       " 3: <datasets.waymo.waymo_sourceloader.WaymoCameraData at 0x7f9b527d3700>,\n",
       " 4: <datasets.waymo.waymo_sourceloader.WaymoCameraData at 0x7f9b527a6f10>}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cameras = dataset.pixel_source.camera_data\n",
    "camera_0 = cameras[1]\n",
    "\n",
    "poses = camera_0.cam_to_worlds\n",
    "intrinsic = camera_0.intrinsics[0]\n",
    "fov = 2 * torch.atan2(intrinsic[0, 2], intrinsic[0, 0])  # 计算视场角 (FOV)\n",
    "\n",
    "import math\n",
    "\n",
    "pose = poses[1]     # 4x4\n",
    "cx = pose[0, 3]\n",
    "cy = pose[1, 3]\n",
    "angle = math.atan2(pose[1, 0], pose[0, 0])\n",
    "cameras\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "7e62b5eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T05:32:59.624908Z",
     "start_time": "2024-12-17T05:32:44.912209Z"
    }
   },
   "source": [
    "torch.save(cameras, 'notebook/data/cameras.pth')  # 将相机数据保存到磁盘\n",
    "torch.save(points, 'notebook/data/points.pth')\n",
    "torch.save(grounds, 'notebook/data/grounds.pth')\n",
    "torch.save(flow_class, 'notebook/data/flow_class.pth')\n"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56b45f29e06c1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.mytools import Camera, Grid2d, CameraSet, Grid2dNumba\n",
    "grid = Grid2d(points, grounds, flow_class, cameras)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e87d327e785802",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_numba = Grid2dNumba(grid, radius=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b434731815240dfa",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "area_coverage = grid_numba.get_area_coverage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f85487e4870c534",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(area_coverage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692850f13aba2d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "map = grid.get_hot_map()\n",
    "\n",
    "map.shape, grid.voxel_grid_2d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f364d425535a977c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(map.numpy(), cmap='hot', interpolation='nearest')\n",
    "plt.title('Voxel Grid')\n",
    "plt.xlabel('Voxel X')\n",
    "plt.ylabel('Voxel Y')\n",
    "plt.colorbar(label='Point Count')\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b89694bdebcdd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "coverages = []\n",
    "for cam in cameras.values():\n",
    "    print(cam)\n",
    "    coverages.append(grid.get_camera_set_coverage(CameraSet(cam.cam_to_worlds, cam.intrinsics)))\n",
    "print(coverages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bd78f3cda8b500",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = Camera(pose, intrinsic)\n",
    "grid.get_camera_coverage(camera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159725b9f9bb01da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
